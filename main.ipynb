{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Telecom ETL\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define schema for the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema = StructType([StructField(\"imsi\",StringType(), False),\n",
    "                     StructField(\"imei\",StringType(), True),\n",
    "                     StructField(\"cell\",IntegerType(), False),\n",
    "                     StructField(\"lac\",IntegerType(), False),\n",
    "                     StructField(\"eventType\",StringType(), True),\n",
    "                     StructField(\"eventTs\",TimestampType(), False),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data with specified schema and delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-----+-----+---------+-------------------+------------+\n",
      "|imsi           |imei           |cell |lac  |eventType|eventTs            |filename    |\n",
      "+---------------+---------------+-----+-----+---------+-------------------+------------+\n",
      "|310120265624299|490154203237518|1234 |99   |1        |2020-06-15 07:45:43|someFileName|\n",
      "|310120265624299|490154203237518|5432 |54   |2        |2020-06-15 12:12:43|someFileName|\n",
      "|310120265624299|490154203237518|4321 |54   |1        |2020-06-15 15:41:43|someFileName|\n",
      "|310120265624299|490154203237518|4657 |99   |4        |2020-06-15 19:11:43|someFileName|\n",
      "|310120265624299|490154203237518|1234 |99   |3        |2020-06-15 20:00:43|someFileName|\n",
      "|310120265624234|490154203237543|123  |22   |1        |2020-06-15 12:12:43|someFileName|\n",
      "|310120265624234|490154203237543|456  |21   |1        |2020-06-15 15:31:43|someFileName|\n",
      "|310120265624234|490154203237543|567  |65   |2        |2020-06-15 17:53:43|someFileName|\n",
      "|310120265624234|490154203237543|543  |66   |2        |2020-06-15 20:13:43|someFileName|\n",
      "|310120265624234|490154203237543|4978 |33   |4        |2020-06-15 22:12:43|someFileName|\n",
      "|310120265624654|490154203237654|4367 |22   |1        |2020-06-15 12:12:43|someFileName|\n",
      "|310120265624123|490154203231245|2435 |11   |1        |2020-06-15 12:12:43|someFileName|\n",
      "|310120265627654|490154203235432|1235 |43   |1        |2020-06-15 12:12:43|someFileName|\n",
      "|null           |3214324134     |21421|12421|2        |2020-06-15 12:12:43|someFileName|\n",
      "|214214         |12421412421124 |null |124  |1        |2020-06-15 12:12:43|someFileName|\n",
      "|214214         |12421412421124 |11   |null |1        |2020-06-15 12:12:43|someFileName|\n",
      "|214214         |12421412421124 |11   |444  |1        |null               |someFileName|\n",
      "+---------------+---------------+-----+-----+---------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"delimiter\",\"|\")\\\n",
    ".option(\"header\",'false')\\\n",
    ".csv(\"ercsn_4g_20200512182929_part02.csv_processing\",schema=schema)\\\n",
    ".withColumn(\"filename\",lit(\"someFileName\"))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter rejected records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-----+-----+---------+-------------------+------------+\n",
      "|  imsi|          imei| cell|  lac|eventType|            eventTs|    filename|\n",
      "+------+--------------+-----+-----+---------+-------------------+------------+\n",
      "|  null|    3214324134|21421|12421|        2|2020-06-15 12:12:43|someFileName|\n",
      "|214214|12421412421124| null|  124|        1|2020-06-15 12:12:43|someFileName|\n",
      "|214214|12421412421124|   11| null|        1|2020-06-15 12:12:43|someFileName|\n",
      "|214214|12421412421124|   11|  444|        1|               null|someFileName|\n",
      "+------+--------------+-----+-----+---------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rejected_df = df.filter((col(\"imsi\").isNull()) | (col(\"cell\").isNull()) | (col(\"lac\").isNull())| (col(\"eventTs\").isNull()))\n",
    "rejected_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive new columns and filter valid records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+----+---+---------+------------+-------+--------+-------------------+\n",
      "|           imsi|           imei|cell|lac|eventType|    filename|    tac|     snr|           event_ts|\n",
      "+---------------+---------------+----+---+---------+------------+-------+--------+-------------------+\n",
      "|310120265624299|490154203237518|1234| 99|        1|someFileName|4901542|03237518|2020-06-15 07:45:43|\n",
      "|310120265624299|490154203237518|5432| 54|        2|someFileName|4901542|03237518|2020-06-15 12:12:43|\n",
      "|310120265624299|490154203237518|4321| 54|        1|someFileName|4901542|03237518|2020-06-15 15:41:43|\n",
      "|310120265624299|490154203237518|4657| 99|        4|someFileName|4901542|03237518|2020-06-15 19:11:43|\n",
      "|310120265624299|490154203237518|1234| 99|        3|someFileName|4901542|03237518|2020-06-15 20:00:43|\n",
      "|310120265624234|490154203237543| 123| 22|        1|someFileName|4901542|03237543|2020-06-15 12:12:43|\n",
      "|310120265624234|490154203237543| 456| 21|        1|someFileName|4901542|03237543|2020-06-15 15:31:43|\n",
      "|310120265624234|490154203237543| 567| 65|        2|someFileName|4901542|03237543|2020-06-15 17:53:43|\n",
      "|310120265624234|490154203237543| 543| 66|        2|someFileName|4901542|03237543|2020-06-15 20:13:43|\n",
      "|310120265624234|490154203237543|4978| 33|        4|someFileName|4901542|03237543|2020-06-15 22:12:43|\n",
      "|310120265624654|490154203237654|4367| 22|        1|someFileName|4901542|03237654|2020-06-15 12:12:43|\n",
      "|310120265624123|490154203231245|2435| 11|        1|someFileName|4901542|03231245|2020-06-15 12:12:43|\n",
      "|310120265627654|490154203235432|1235| 43|        1|someFileName|4901542|03235432|2020-06-15 12:12:43|\n",
      "+---------------+---------------+----+---+---------+------------+-------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_cols_df = df.withColumn(\"tac\", \n",
    "                            when(col(\"imei\").isNull() | (length(col(\"imei\")) < 15), \"-99999\")\n",
    "                            .otherwise(substring(col(\"imei\"), 0, 7))) \\\n",
    "                .withColumn(\"snr\", \n",
    "                            when(col(\"imei\").isNull() | (length(col(\"imei\")) < 15), \"-99999\")\n",
    "                            .otherwise(substring(col(\"imei\"), 8, 13)))\\\n",
    "                .withColumn(\"event_ts\",\n",
    "                            to_timestamp(col(\"eventTs\"),'YYYY-mm-dd HH:MM:SS'))\\\n",
    "                .filter((col(\"imsi\").isNotNull()) & (col(\"cell\").isNotNull()) & (col(\"lac\").isNotNull()) & (col(\"eventTs\").isNotNull()))\n",
    "\n",
    "# Drop redundant columns\n",
    "df_dropped = new_cols_df.drop(\"eventTs\")\n",
    "df_dropped.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records: 17\n",
      "Total Number of Accepted records: 13\n",
      "Total Number of rejected records: 4\n",
      "Total Number of processed records: 17\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Number of records: {df.count()}\")\n",
    "print(f\"Total Number of Accepted records: {df_dropped.count()}\")\n",
    "print(f\"Total Number of rejected records: {rejected_df.count()}\")\n",
    "print(f\"Total Number of processed records: {rejected_df.count() + df_dropped.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select final columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+--------+---------------+----+---+---------+-------------------+------------+\n",
      "|           imsi|    tac|     snr|           imei|cell|lac|eventType|           event_ts|    filename|\n",
      "+---------------+-------+--------+---------------+----+---+---------+-------------------+------------+\n",
      "|310120265624299|4901542|03237518|490154203237518|1234| 99|        1|2020-06-15 07:45:43|someFileName|\n",
      "|310120265624299|4901542|03237518|490154203237518|5432| 54|        2|2020-06-15 12:12:43|someFileName|\n",
      "|310120265624299|4901542|03237518|490154203237518|4321| 54|        1|2020-06-15 15:41:43|someFileName|\n",
      "|310120265624299|4901542|03237518|490154203237518|4657| 99|        4|2020-06-15 19:11:43|someFileName|\n",
      "|310120265624299|4901542|03237518|490154203237518|1234| 99|        3|2020-06-15 20:00:43|someFileName|\n",
      "|310120265624234|4901542|03237543|490154203237543| 123| 22|        1|2020-06-15 12:12:43|someFileName|\n",
      "|310120265624234|4901542|03237543|490154203237543| 456| 21|        1|2020-06-15 15:31:43|someFileName|\n",
      "|310120265624234|4901542|03237543|490154203237543| 567| 65|        2|2020-06-15 17:53:43|someFileName|\n",
      "|310120265624234|4901542|03237543|490154203237543| 543| 66|        2|2020-06-15 20:13:43|someFileName|\n",
      "|310120265624234|4901542|03237543|490154203237543|4978| 33|        4|2020-06-15 22:12:43|someFileName|\n",
      "|310120265624654|4901542|03237654|490154203237654|4367| 22|        1|2020-06-15 12:12:43|someFileName|\n",
      "|310120265624123|4901542|03231245|490154203231245|2435| 11|        1|2020-06-15 12:12:43|someFileName|\n",
      "|310120265627654|4901542|03235432|490154203235432|1235| 43|        1|2020-06-15 12:12:43|someFileName|\n",
      "+---------------+-------+--------+---------------+----+---+---------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = df_dropped.select(\"imsi\",\"tac\",\"snr\",\"imei\",\"cell\",\"lac\",\"eventType\",\"event_ts\",\"filename\")\n",
    "\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Spark DataFrame to Pandas DataFrame\n",
    "##### Save the Pandas DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\python\\pyspark\\sql\\pandas\\conversion.py:251: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "pandas_df = final_df.toPandas()\n",
    "\n",
    "# Save the Pandas DataFrame to a CSV file\n",
    "pandas_df.to_csv(\"C:/Users/Ahmed Ashraf/Desktop/Telecom-ETL/Final_data/processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stop the SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
